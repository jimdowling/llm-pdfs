{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8bef9a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdbac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-02 15:21:32.101701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 15:21:32.632089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/targets/x86_64-linux/lib:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server:/srv/hops/hadoop/lib/native:/srv/hops/anaconda/envs/theenv/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-02-02 15:21:32.632206: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/targets/x86_64-linux/lib:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server:/srv/hops/hadoop/lib/native:/srv/hops/anaconda/envs/theenv/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-02-02 15:21:32.632213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "from functions.prompt_engineering import get_context_and_source\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b341f6d5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78015c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/1143\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01f64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'documents' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name=\"documents\", \n",
    "    version=1,\n",
    ")   \n",
    "\n",
    "# Initialize serving\n",
    "feature_view.init_serving(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1a1125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 15:22:01,385 main ERROR Cannot access RandomAccessFile java.io.IOException: Could not create directory /srv/hops/hadoop-3.2.0.12-EE-SNAPSHOT/logs java.io.IOException: Could not create directory /srv/hops/hadoop-3.2.0.12-EE-SNAPSHOT/logs\n",
      "\tat org.apache.logging.log4j.core.util.FileUtils.mkdir(FileUtils.java:128)\n",
      "\tat org.apache.logging.log4j.core.util.FileUtils.makeParentDirs(FileUtils.java:141)\n",
      "\tat org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$RollingRandomAccessFileManagerFactory.createManager(RollingRandomAccessFileManager.java:231)\n",
      "\tat org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$RollingRandomAccessFileManagerFactory.createManager(RollingRandomAccessFileManager.java:204)\n",
      "\tat org.apache.logging.log4j.core.appender.AbstractManager.getManager(AbstractManager.java:144)\n",
      "\tat org.apache.logging.log4j.core.appender.OutputStreamManager.getManager(OutputStreamManager.java:100)\n",
      "\tat org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager.getRollingRandomAccessFileManager(RollingRandomAccessFileManager.java:107)\n",
      "\tat org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender$Builder.build(RollingRandomAccessFileAppender.java:132)\n",
      "\tat org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender$Builder.build(RollingRandomAccessFileAppender.java:53)\n",
      "\tat org.apache.logging.log4j.core.config.plugins.util.PluginBuilder.build(PluginBuilder.java:124)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createPluginObject(AbstractConfiguration.java:1138)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1063)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1055)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.doConfigure(AbstractConfiguration.java:664)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.initialize(AbstractConfiguration.java:258)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.start(AbstractConfiguration.java:304)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:621)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:694)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:711)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:253)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47)\n",
      "\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:309)\n",
      "\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:86)\n",
      "\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:99)\n",
      "\tat org.apache.log4j.Category.<init>(Category.java:188)\n",
      "\tat org.apache.log4j.Logger.<init>(Logger.java:57)\n",
      "\tat org.apache.log4j.spi.RootLogger.<init>(RootLogger.java:39)\n",
      "\tat org.apache.log4j.LogManager.<clinit>(LogManager.java:72)\n",
      "\tat org.apache.log4j.Logger.getLogger(Logger.java:40)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:262)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.<init>(Log4JLogger.java:108)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.createLogFromClass(LogFactoryImpl.java:1025)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.discoverLogImplementation(LogFactoryImpl.java:844)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:541)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:292)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:269)\n",
      "\tat org.apache.commons.logging.LogFactory.getLog(LogFactory.java:657)\n",
      "\tat org.apache.hadoop.fs.FileSystem.<clinit>(FileSystem.java:139)\n",
      "\n",
      "2024-02-02 15:22:01,389 main ERROR Could not create plugin of type class org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender for element RollingRandomAccessFile: java.lang.IllegalStateException: ManagerFactory [org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$RollingRandomAccessFileManagerFactory@1bd4fdd] unable to create manager for [/srv/hops/hadoop/logs/hadoop.log] with data [org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$FactoryData@55183b20] java.lang.IllegalStateException: ManagerFactory [org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$RollingRandomAccessFileManagerFactory@1bd4fdd] unable to create manager for [/srv/hops/hadoop/logs/hadoop.log] with data [org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager$FactoryData@55183b20]\n",
      "\tat org.apache.logging.log4j.core.appender.AbstractManager.getManager(AbstractManager.java:146)\n",
      "\tat org.apache.logging.log4j.core.appender.OutputStreamManager.getManager(OutputStreamManager.java:100)\n",
      "\tat org.apache.logging.log4j.core.appender.rolling.RollingRandomAccessFileManager.getRollingRandomAccessFileManager(RollingRandomAccessFileManager.java:107)\n",
      "\tat org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender$Builder.build(RollingRandomAccessFileAppender.java:132)\n",
      "\tat org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender$Builder.build(RollingRandomAccessFileAppender.java:53)\n",
      "\tat org.apache.logging.log4j.core.config.plugins.util.PluginBuilder.build(PluginBuilder.java:124)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createPluginObject(AbstractConfiguration.java:1138)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1063)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1055)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.doConfigure(AbstractConfiguration.java:664)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.initialize(AbstractConfiguration.java:258)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.start(AbstractConfiguration.java:304)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:621)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:694)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:711)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:253)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47)\n",
      "\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:309)\n",
      "\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:86)\n",
      "\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:99)\n",
      "\tat org.apache.log4j.Category.<init>(Category.java:188)\n",
      "\tat org.apache.log4j.Logger.<init>(Logger.java:57)\n",
      "\tat org.apache.log4j.spi.RootLogger.<init>(RootLogger.java:39)\n",
      "\tat org.apache.log4j.LogManager.<clinit>(LogManager.java:72)\n",
      "\tat org.apache.log4j.Logger.getLogger(Logger.java:40)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:262)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.<init>(Log4JLogger.java:108)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.createLogFromClass(LogFactoryImpl.java:1025)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.discoverLogImplementation(LogFactoryImpl.java:844)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:541)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:292)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:269)\n",
      "\tat org.apache.commons.logging.LogFactory.getLog(LogFactory.java:657)\n",
      "\tat org.apache.hadoop.fs.FileSystem.<clinit>(FileSystem.java:139)\n",
      "\n",
      "2024-02-02 15:22:01,389 main ERROR Unable to invoke factory method in class org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender for element RollingRandomAccessFile: java.lang.IllegalStateException: No factory method found for class org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender java.lang.IllegalStateException: No factory method found for class org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender\n",
      "\tat org.apache.logging.log4j.core.config.plugins.util.PluginBuilder.findFactoryMethod(PluginBuilder.java:260)\n",
      "\tat org.apache.logging.log4j.core.config.plugins.util.PluginBuilder.build(PluginBuilder.java:136)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createPluginObject(AbstractConfiguration.java:1138)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1063)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.createConfiguration(AbstractConfiguration.java:1055)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.doConfigure(AbstractConfiguration.java:664)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.initialize(AbstractConfiguration.java:258)\n",
      "\tat org.apache.logging.log4j.core.config.AbstractConfiguration.start(AbstractConfiguration.java:304)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:621)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:694)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:711)\n",
      "\tat org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:253)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155)\n",
      "\tat org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47)\n",
      "\tat org.apache.logging.log4j.LogManager.getContext(LogManager.java:309)\n",
      "\tat org.apache.log4j.Hierarchy$PrivateLogManager.getContext(Hierarchy.java:86)\n",
      "\tat org.apache.log4j.Hierarchy.getContext(Hierarchy.java:99)\n",
      "\tat org.apache.log4j.Category.<init>(Category.java:188)\n",
      "\tat org.apache.log4j.Logger.<init>(Logger.java:57)\n",
      "\tat org.apache.log4j.spi.RootLogger.<init>(RootLogger.java:39)\n",
      "\tat org.apache.log4j.LogManager.<clinit>(LogManager.java:72)\n",
      "\tat org.apache.log4j.Logger.getLogger(Logger.java:40)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:262)\n",
      "\tat org.apache.commons.logging.impl.Log4JLogger.<init>(Log4JLogger.java:108)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.createLogFromClass(LogFactoryImpl.java:1025)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.discoverLogImplementation(LogFactoryImpl.java:844)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:541)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:292)\n",
      "\tat org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:269)\n",
      "\tat org.apache.commons.logging.LogFactory.getLog(LogFactory.java:657)\n",
      "\tat org.apache.hadoop.fs.FileSystem.<clinit>(FileSystem.java:139)\n",
      "\n",
      "2024-02-02 15:22:01,390 main ERROR Null object returned for RollingRandomAccessFile in Appenders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-SNAPSHOT/share/hadoop/common/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-SNAPSHOT/share/hadoop/hdfs/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 7 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "# Get the Mistral model from Model Registry\n",
    "mistral_model = mr.get_model(\n",
    "    name=\"mistral_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the Mistral model files to a local directory\n",
    "saved_model_dir = mistral_model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d6286",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Model Loading </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363b1325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe44835ad3443cc9800aacec41b7297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70848b9d8a84f2882f2aafbcdd85b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f008e3049e4517989b6533b3482e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd55b2a6ec744c73b52dbcbc39e38623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec8a3e8703e49e18d9adbde2cac4679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8581bc79be4ba7ad0b00660506aee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2707608d65a94687b7ca307eb7b035ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67df9aa044ed44ffb452255a3e54094b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a50d557e754fd896116302075baf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb74270164b24d61823ce0ba3c1976a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379bb3ec2aa84c1982c23b9acd2dd7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f50fb5c087b47a5a1d5f27fa931e977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb264bcbd556444497f807a1fb837b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b189a1002974cdcb63b2ef50ba1ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the Sentence Transformer\n",
    "sentence_transformer = SentenceTransformer(\n",
    "    'all-MiniLM-L6-v2',\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ea8979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731a29e87aa94011993b420d1c2598c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39137655780e4f9092b1cc172ec50448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f2e578cb604eff9395650f0e99c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f1622edb2c41058517ed90c2c61935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23015883155742d798fcf7336c3ada5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a2f85ecef74d6794368e5ed0163714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcba1e7e46704810a90d4ef71fd9cf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244e56c5ae7e4342886d1ca26e620b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a model from the saved model directory\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  saved_model_dir,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca77c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from the saved model directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    saved_model_dir,\n",
    ")\n",
    "\n",
    "# Set the pad token to the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Set the padding side to \"right\" to remove warnings\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0258e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚õìÔ∏è LLM Chain </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be93c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "# Create a text generation pipeline using the loaded model and tokenizer\n",
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,                          # The pre-trained language model for text generation\n",
    "    tokenizer=tokenizer,                  # The tokenizer corresponding to the language model\n",
    "    task=\"text-generation\",               # Specify the task as text generation\n",
    "    temperature=0.2,                      # Controls the randomness of the generation (higher values for more randomness)\n",
    "    repetition_penalty=1.5,               # Controls the penalty for repeating tokens in generated text\n",
    "    return_full_text=True,                # Return the full generated text instead of just the generated tokens\n",
    "    max_new_tokens=750,                   # Limit the maximum number of newly generated tokens\n",
    "    pad_token_id=tokenizer.eos_token_id,  # Use the end-of-sequence token as the padding token\n",
    "    do_sample=True,                       # Enable sampling during text generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce018e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template for generating prompts\n",
    "prompt_template = \"\"\"\n",
    "[INST] \n",
    "Instruction: Prioritize brevity and clarity in responses. \n",
    "Avoid unnecessary repetition and keep answers concise, adhering to a maximum of 750 characters. \n",
    "Eliminate redundant phrases and sentences. \n",
    "If details are repeated, provide them only once for better readability. \n",
    "Focus on delivering key information without unnecessary repetition. \n",
    "If a concept is already conveyed, there's no need to restate it. Ensure responses remain clear and to the point.\n",
    "Make sure you do not repeat any sentences in your answer.\n",
    "[/INST]\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "### CONTEXT:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "[INST]{question}[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e995e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Hugging Face pipeline for Mistral LLM using the text generation pipeline\n",
    "mistral_llm = HuggingFacePipeline(\n",
    "    pipeline=text_generation_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae18d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3260dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ConversationBufferWindowMemory with specified configuration\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3,                         # Number of turns to remember in the conversation buffer\n",
    "    memory_key=\"chat_history\",   # Key to store the conversation history in memory\n",
    "    input_key=\"question\",        # Key to access the input question in the conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142c1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM chain \n",
    "llm_chain = LLMChain(\n",
    "    llm=mistral_llm, \n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e5c9d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Reranking </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d72150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reranker():\n",
    "    reranker = FlagReranker(\n",
    "        'BAAI/bge-reranker-large', \n",
    "        use_fp16=True,\n",
    "    ) \n",
    "    return reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed462e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae12da5f29b4e55a2f6203392f05694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a73461b12e944078e5c6a174a2ddbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01414405965b45f9b445de8d724bd218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ea4e6173744cec8168159cd2db5e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e4c668f35d4b45868a483579081ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345487a9712d474eaa9bb354d0e3cdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve a reranker\n",
    "reranker = get_reranker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f20b5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c591c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üóÑÔ∏è Context Retrieval </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c90e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Question Example\n",
    "user_input = 'What are the best risk reporting practices?' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a92a2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve reranked context and source\n",
    "context, source = get_context_and_source(\n",
    "    user_input, \n",
    "    sentence_transformer,\n",
    "    feature_view, \n",
    "    reranker,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d051e50",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üöÄ Model Inference </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c2e653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best risk reporting practices involve generating aggregate and up-to-date risk data quickly and efficiently, covering all significant risk areas and providing customized information tailored to the recipient's needs. Additionally, frequent updates and incorporating forward-looking assessments are essential. Clear communication and comprehensibility are crucial factors in ensuring helpful and productive risk reporting. Coverage must extend beyond basic financial metrics to address important aspects such as asset quality, cash flow, earnings per share, equity valuation, interest rates, exchange rates, commodities prices, legal issues, tax laws, among others. Adapting to evolving demands and supervisor queries is equally vital. Finally, integrating robust systems and controls into risk reporting helps improve accuracy and mitigate fraudulent activities. Proper training programs for staff handling sensitive financial documents and IT infrastructure capabilities are fundamental prerequisites for successful risk reporting initiatives. Implementing automation solutions like AI algorithms, machine learning tools, cloud computing services, mobile applications, IoT devices, and automated workflows enhances efficiency and reduces human error probabilities significantly. Establishing performance indicators and benchmarks against competitors or peer groups facilitates improved strategic planning and quick identification of weaknesses. Effective collaboration and sharing of resources amongst team members promote innovation and increase chances of success. Granting access privileges judiciously ensures security protocols protect confidential client and company info from unauthorized individuals. Employing third parties wisely contributes positively towards achieving optimal outcomes. Regulatory compliance guidelines and ethical conduct codes serve as valuable references throughout the entire process. Continuous monitoring and prompt rectification of deficiencies help streamline operations and minimize losses. Incorporating user feedback and suggestions improves system usability considerably. Focusing on customer satisfaction keeps service providers accountable and motivated to excel in their respective roles. Encouraging open dialogue fosters trust and transparency whilst enabling swift resolution of concerns. Lastly, maintaining proper documentation provides historical records needed for trend analyses and progress tracking purposes. It enables businesses to learn from mistakes made previously and avoid repeating similar blunders moving ahead. Overall, implementing rigorous risk reporting standards leads to enhanced organizational resiliency and sustainable growth prospects. By consistently applying these tenets, organizations demonstrate commitment toward optimizing resource utilization and creating long-term value for stakeholders.\n",
      "\n",
      "References:\n",
      " - bcbs239.pdf(https://drive.google.com/file/d/1lPbO28MoOc7XxaSbvpJiaC6VAeUwTqyA/preview?usp=drivesdk): Page: 18, Paragraph: 1\n",
      " - bcbs239.pdf(https://drive.google.com/file/d/1lPbO28MoOc7XxaSbvpJiaC6VAeUwTqyA/preview?usp=drivesdk): Page: 27, Paragraph: 1\n",
      " - bcbs239.pdf(https://drive.google.com/file/d/1lPbO28MoOc7XxaSbvpJiaC6VAeUwTqyA/preview?usp=drivesdk): Page: 19, Paragraph: 1\n"
     ]
    }
   ],
   "source": [
    "# Generate model response\n",
    "model_output = llm_chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": user_input,\n",
    "})\n",
    "\n",
    "print(model_output['text'].split('### RESPONSE:\\n')[-1] + source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2b7c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a3d37d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptability refers to flexibility and ability to aggregate risk data according to requesteds scenarios or economic events. It allows for efficient assessment, quick decisions, and supporting stress testing and scenario analyzes. Also, it caters to changes in organization structure, threats sources, transmission mechanisms, trusted paths, and trustworthiness attributes.\n",
      "\n",
      "References:\n",
      " - bcbs239.pdf(https://drive.google.com/file/d/1lPbO28MoOc7XxaSbvpJiaC6VAeUwTqyA/preview?usp=drivesdk): Page: 17, Paragraph: 1\n",
      " - NIST.SP.800-53r5.pdf(https://drive.google.com/file/d/1i_pJ-RfbJKw1McBmkoe8d9DCDi-2C-pS/preview?usp=drivesdk): Page: 449, Paragraph: 2\n",
      " - pub-ch-bank-supervision-process.pdf(https://drive.google.com/file/d/160FaGKMZPXDGkR_BUDysf-AtZ1eyuWWW/preview?usp=drivesdk): Page: 76, Paragraph: 4\n"
     ]
    }
   ],
   "source": [
    "user_input = 'What is Adaptability?'\n",
    "\n",
    "context, source = get_context_and_source(\n",
    "    user_input, \n",
    "    sentence_transformer,\n",
    "    feature_view, \n",
    "    reranker,\n",
    ")\n",
    "\n",
    "model_output = llm_chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": user_input,\n",
    "})\n",
    "\n",
    "print(model_output['text'].split('### RESPONSE:\\n')[-1] + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41317c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk management involves identifying, measuring, and controlling various forms of risk faced by a bank. It encompasses processes related to Credit, Interest Rate, Liquidity, Price, Operational, Compliance, Strategic, and Reputation risks.\n",
      "\n",
      "References:\n",
      " - pub-ch-bank-supervision-process.pdf(https://drive.google.com/file/d/160FaGKMZPXDGkR_BUDysf-AtZ1eyuWWW/preview?usp=drivesdk): Page: 128, Paragraph: 2\n",
      " - pub-ch-bank-supervision-process.pdf(https://drive.google.com/file/d/160FaGKMZPXDGkR_BUDysf-AtZ1eyuWWW/preview?usp=drivesdk): Page: 129, Paragraph: 2\n",
      " - pub-ch-community-bank-supervision.pdf(https://drive.google.com/file/d/1ZKd_V5cl5RvPa_DJiKxXKPvCuueCt6Fg/preview?usp=drivesdk): Page: 18, Paragraph: 3\n"
     ]
    }
   ],
   "source": [
    "user_input = 'What is a risk management?'\n",
    "\n",
    "context, source = get_context_and_source(\n",
    "    user_input, \n",
    "    sentence_transformer,\n",
    "    feature_view, \n",
    "    reranker,\n",
    ")\n",
    "\n",
    "model_output = llm_chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": user_input,\n",
    "})\n",
    "\n",
    "print(model_output['text'].split('### RESPONSE:\\n')[-1] + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3925a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of maintaining an up-to-date data-flow diagram is to prevent account data from being overlooked and knowingly left unsecure. It also helps identify critical connection points and control flows within the network.\n",
      "\n",
      "References:\n",
      " - PCI-DSS-v4_0.pdf(https://drive.google.com/file/d/1ULFjxgNXNVFmZnDc3r69iKtUUvYmUIAu/preview?usp=drivesdk): Page: 50, Paragraph: 2\n",
      " - PCI-DSS-v4_0.pdf(https://drive.google.com/file/d/1ULFjxgNXNVFmZnDc3r69iKtUUvYmUIAu/preview?usp=drivesdk): Page: 317, Paragraph: 2\n",
      " - PCI-DSS-v4_0.pdf(https://drive.google.com/file/d/1ULFjxgNXNVFmZnDc3r69iKtUUvYmUIAu/preview?usp=drivesdk): Page: 277, Paragraph: 2\n"
     ]
    }
   ],
   "source": [
    "user_input = 'What is the purpose of maintaining an up-to-date data-flow diagram?'\n",
    "\n",
    "context, source = get_context_and_source(\n",
    "    user_input, \n",
    "    sentence_transformer,\n",
    "    feature_view, \n",
    "    reranker,\n",
    ")\n",
    "\n",
    "model_output = llm_chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": user_input,\n",
    "})\n",
    "\n",
    "print(model_output['text'].split('### RESPONSE:\\n')[-1] + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c146ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security and privacy controls play a crucial role in protecting organizational operations, assets, individuals, other organizations, and the nation against potential adversaries. They ensure compliance with mandates such as Office of Management and Budget circulars and legislations like the Federal Information Security Modernization Act. By using appropriate security and privacy controls, organizations aim to achieve trustworthy, secure, and resilient systems.\n",
      "\n",
      "References:\n",
      " - NIST.SP.800-53r5.pdf(https://drive.google.com/file/d/1i_pJ-RfbJKw1McBmkoe8d9DCDi-2C-pS/preview?usp=drivesdk): Page: 29, Paragraph: 1\n",
      " - NIST.SP.800-53r5.pdf(https://drive.google.com/file/d/1i_pJ-RfbJKw1McBmkoe8d9DCDi-2C-pS/preview?usp=drivesdk): Page: 34, Paragraph: 1\n",
      " - NIST.SP.800-53r5.pdf(https://drive.google.com/file/d/1i_pJ-RfbJKw1McBmkoe8d9DCDi-2C-pS/preview?usp=drivesdk): Page: 37, Paragraph: 1\n"
     ]
    }
   ],
   "source": [
    "user_input = 'Why are security and privacy controls important?'\n",
    "\n",
    "context, source = get_context_and_source(\n",
    "    user_input, \n",
    "    sentence_transformer,\n",
    "    feature_view, \n",
    "    reranker,\n",
    ")\n",
    "\n",
    "model_output = llm_chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": user_input,\n",
    "})\n",
    "\n",
    "print(model_output['text'].split('### RESPONSE:\\n')[-1] + source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ee5f2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
